{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Implement the bagging based Ensemble model using CART(Classification and Regression trees) as base learners. No of base learners=100. Use cross validation as the model estimation method."
      ],
      "metadata": {
        "id": "1SCH5Gdnor__"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_SUIpF1i2kK",
        "outputId": "c6c5b77c-6d9e-4c09-969c-52d9d618a6a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg','pass','pres','skin','test','mass','pedi','age','class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "Kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "\n",
        "#change 'base_estimator' to 'estimator'\n",
        "model = BaggingClassifier(estimator=cart, n_estimators=num_trees, random_state=7)\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
        "average_accuracy = sum(results)/len(results)\n",
        "print(\"Average accuracy: \", average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SaZ14K2j8NI",
        "outputId": "e9c07afb-cae1-4b44-c387-1bd49217b98f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy:  0.7578263841421736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Adaboost Ensemble model for classification using 10 base learners and cross validation\n"
      ],
      "metadata": {
        "id": "bu_6f6Yopk8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg','pass','pres','skin','test','mass','pedi','age','class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPAMm0q2kBLz",
        "outputId": "f1f83d52-0350-4058-948d-43ddd20e2c87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = df.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "Kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "cart = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "model = AdaBoostClassifier(n_estimators=num_trees, random_state=7)\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
        "average_accuracy = sum(results)/len(results)\n",
        "print(\"Average accuracy: \", average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR7qQ4VKqXL3",
        "outputId": "8a2fcddd-a25e-4de4-f6e0-dc43a153517b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy:  0.7578605604921395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the bagging based Ensemble model using k-Nearest Neighbor Classifier as base learners. No of base learners=100. Use cross validation as the model estimation method."
      ],
      "metadata": {
        "id": "f-zx8UeisY-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg','pass','pres','skin','test','mass','pedi','age','class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GGABKM2rFEg",
        "outputId": "13df7d2d-f9e6-491b-8789-68d53c8110ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "#Set shuffle=True in KFold\n",
        "Kfold = model_selection.KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "knn = KNeighborsClassifier()\n",
        "num_learners = 100\n",
        "model = BaggingClassifier(estimator=knn,n_estimators=num_learners, random_state=7)\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=Kfold)\n",
        "average_accuracy = sum(results)/len(results)\n",
        "print(\"Average accuracy: \", average_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5XcUIX1sdU1",
        "outputId": "cea6951e-322f-48ff-bce1-c727a3b163e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy:  0.7188140806561858\n"
          ]
        }
      ]
    }
  ]
}